{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/r01vghr16hbb2gb9rwm76yn40000gn/T/ipykernel_1727/1294756053.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm.autonotebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "    # Basic \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # MODEL\n",
    "    INPUT_DIM = 28 * 28 \n",
    "    Z_DIM = 20\n",
    "    H_DIM  = 200\n",
    "    \n",
    "    # TRAINING \n",
    "    NUM_EPOCHS = 10\n",
    "    BATCH_SIZE = 32\n",
    "    LR_RATE = 3e-4\n",
    "    \n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img2hidden = nn.Linear(params.INPUT_DIM, params.H_DIM)\n",
    "        self.hidden2mean = nn.Linear(params.H_DIM, params.Z_DIM)\n",
    "        self.hidden2std = nn.Linear(params.H_DIM, params.Z_DIM)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = F.relu(self.img2hidden(x))\n",
    "        mu = self.hidden2mean(hidden)\n",
    "        std = self.hidden2std(hidden)\n",
    "        \n",
    "        return mu, std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.z2hidden = nn.Linear(params.Z_DIM, params.H_DIM)\n",
    "        self.hidden2img = nn.Linear(params.H_DIM, params.INPUT_DIM)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        new_h = F.relu(self.z2hidden(z))\n",
    "        img = torch.sigmoid(self.hidden2img(new_h))\n",
    "        return img \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, params, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, std = self.encoder(x)\n",
    "\n",
    "        # Sample from latent distribution from encoder\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z_reparametrized = mu + std * epsilon\n",
    "        \n",
    "        img = self.decode(z_reparametrized)\n",
    "        \n",
    "        return img, mu, std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(params):\n",
    "    encoder = Encoder(params)\n",
    "    decoder = Decoder(params)\n",
    "    model = VAE(params, encoder, decoder)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=params.BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params.LR_RATE)\n",
    "loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(digit,dataset, num_examples=1, ):\n",
    "    images= []\n",
    "    idx = 0\n",
    "    for x, y in dataset:\n",
    "        if y == idx:\n",
    "            images.append(x)\n",
    "            idx += 1\n",
    "        if idx == 10:\n",
    "            break  \n",
    "    \n",
    "    \n",
    "    encodings_digit = []\n",
    "    for d in range(10):\n",
    "        with torch.no_grad():\n",
    "            mu, sigma = model.encode(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
